---
title: "Optimisation et Performance"
order: 42
parent: null
tags: ["python", "performance", "optimization", "profiling"]
---

# Optimisation et Performance

## Introduction

L'optimisation est l'art de rendre votre code Python plus rapide et plus efficace. Cependant, comme le disait Donald Knuth : **"Premature optimization is the root of all evil"** - il faut d'abord mesurer avant d'optimiser.

### Les rÃ¨gles de l'optimisation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LES 3 RÃˆGLES DE L'OPTIMISATION                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  RÃ¨gle 1 : Ne pas optimiser                            â”‚
â”‚  RÃ¨gle 2 : Ne pas optimiser (encore)                   â”‚
â”‚  RÃ¨gle 3 : Profiler d'abord, optimiser ensuite         â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quand optimiser ?

| Situation | Action |
|-----------|--------|
| **Prototype/POC** | ClartÃ© > Performance |
| **FonctionnalitÃ© nouvelle** | Correction > Optimisation |
| **Code lent identifiÃ©** | Profiler puis optimiser |
| **Goulot d'Ã©tranglement** | Optimiser le bottleneck |
| **Ã‰chelle critique** | Optimisation stratÃ©gique |

## Philosophie de l'optimisation

### 1. Mesurer d'abord

```python
import time

def measure_time(func):
    """DÃ©corateur pour mesurer le temps d'exÃ©cution"""
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        end = time.perf_counter()
        print(f"{func.__name__} took {end - start:.4f}s")
        return result
    return wrapper

@measure_time
def slow_function():
    total = 0
    for i in range(1000000):
        total += i
    return total
```

### 2. Identifier les bottlenecks

**Loi de Amdahl** : Optimiser 90% du code qui prend 10% du temps ne sert Ã  rien.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    OÃ¹ passe le temps ?             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 60% DB       â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 30% API externe        â”‚
â”‚  â–ˆâ–ˆâ–ˆ 10% Calculs                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   Optimiser la DB d'abord !
```

### 3. Big O Notation

Comprendre la complexitÃ© algorithmique :

| Notation | Nom | Exemple | Performance |
|----------|-----|---------|-------------|
| **O(1)** | Constant | AccÃ¨s dict/list | Excellent |
| **O(log n)** | Logarithmique | Recherche binaire | TrÃ¨s bon |
| **O(n)** | LinÃ©aire | Boucle simple | Bon |
| **O(n log n)** | Log-linÃ©aire | Tri efficace | Acceptable |
| **O(nÂ²)** | Quadratique | Boucles imbriquÃ©es | Mauvais |
| **O(2â¿)** | Exponentiel | RÃ©cursion naÃ¯ve | Catastrophique |

```python
# O(1) - Excellent
def get_first_element(lst):
    return lst[0]

# O(n) - Bon
def sum_list(lst):
    return sum(lst)

# O(nÂ²) - Mauvais
def has_duplicates_slow(lst):
    for i in range(len(lst)):
        for j in range(i + 1, len(lst)):
            if lst[i] == lst[j]:
                return True
    return False

# O(n) - Beaucoup mieux !
def has_duplicates_fast(lst):
    return len(lst) != len(set(lst))
```

## Techniques d'optimisation Python

### 1. Structures de donnÃ©es appropriÃ©es

```python
import time

# âŒ Mauvais : Liste pour les recherches
def find_in_list(lst, value):
    return value in lst  # O(n)

# âœ… Bon : Set pour les recherches
def find_in_set(s, value):
    return value in s  # O(1)

# Benchmark
numbers_list = list(range(100000))
numbers_set = set(range(100000))

# Liste : ~2ms pour trouver 99999
# Set : ~0.00001ms pour trouver 99999
```

**Choisir la bonne structure** :

| Besoin | Structure | Pourquoi |
|--------|-----------|----------|
| Recherche rapide | `set`, `dict` | O(1) |
| Ordre important | `list` | Maintient l'ordre |
| File FIFO | `collections.deque` | O(1) aux deux bouts |
| Tri auto | `heapq` | O(log n) |
| Comptage | `collections.Counter` | OptimisÃ© |

### 2. ComprÃ©hensions vs Boucles

```python
# âŒ Lent : Boucle classique
result = []
for i in range(1000):
    if i % 2 == 0:
        result.append(i * 2)

# âœ… Plus rapide : ComprÃ©hension de liste
result = [i * 2 for i in range(1000) if i % 2 == 0]

# âœ… Encore mieux si juste itÃ©rer : GÃ©nÃ©rateur
result = (i * 2 for i in range(1000) if i % 2 == 0)
```

### 3. Ã‰viter les concatÃ©nations rÃ©pÃ©tÃ©es

```python
# âŒ TrÃ¨s lent : O(nÂ²)
result = ""
for i in range(10000):
    result += str(i)  # CrÃ©e une nouvelle chaÃ®ne Ã  chaque fois !

# âœ… Rapide : O(n)
result = "".join(str(i) for i in range(10000))
```

### 4. Utiliser les built-ins

Les fonctions intÃ©grÃ©es sont implÃ©mentÃ©es en C :

```python
# âŒ Lent
def sum_list(lst):
    total = 0
    for x in lst:
        total += x
    return total

# âœ… Rapide : Built-in en C
total = sum(lst)

# Autres built-ins rapides
max(lst)
min(lst)
any(lst)
all(lst)
sorted(lst)
```

### 5. Local vs Global

```python
# âŒ Lent : AccÃ¨s global
import math

def calculate_distances(points):
    distances = []
    for p in points:
        distances.append(math.sqrt(p[0]**2 + p[1]**2))
    return distances

# âœ… Rapide : Variable locale
def calculate_distances_fast(points):
    sqrt = math.sqrt  # Cache local
    distances = []
    for p in points:
        distances.append(sqrt(p[0]**2 + p[1]**2))
    return distances
```

## Profiling

### timeit pour micro-benchmarks

```python
import timeit

# Comparer deux approches
list_comp = timeit.timeit(
    '[i*2 for i in range(1000)]',
    number=10000
)

map_func = timeit.timeit(
    'list(map(lambda x: x*2, range(1000)))',
    number=10000
)

print(f"List comprehension: {list_comp:.4f}s")
print(f"Map: {map_func:.4f}s")
```

### cProfile pour profiling complet

```python
import cProfile
import pstats

def main():
    # Votre code Ã  profiler
    data = [i for i in range(100000)]
    squared = [x**2 for x in data]
    return sum(squared)

# Profiler
profiler = cProfile.Profile()
profiler.enable()
main()
profiler.disable()

# Afficher les stats
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(10)  # Top 10
```

### line_profiler pour profiling ligne par ligne

```bash
pip install line_profiler
```

```python
# @profile dÃ©corator
@profile
def slow_function():
    total = 0
    for i in range(10000):
        total += i**2
    return total
```

```bash
kernprof -l -v script.py
```

## MÃ©moire

### memory_profiler

```python
from memory_profiler import profile

@profile
def memory_hungry():
    data = [i for i in range(1000000)]
    data_squared = [x**2 for x in data]
    return sum(data_squared)
```

### GÃ©nÃ©rateurs pour Ã©conomiser la mÃ©moire

```python
# âŒ Consomme beaucoup de mÃ©moire
def read_large_file(filename):
    return [line for line in open(filename)]

# âœ… ItÃ¨re sans tout charger
def read_large_file_gen(filename):
    with open(filename) as f:
        for line in f:
            yield line.strip()

# Utilisation
for line in read_large_file_gen('huge.txt'):
    process(line)
```

### __slots__ pour rÃ©duire la mÃ©moire des objets

```python
# Sans slots : ~300 bytes par instance
class Point:
    def __init__(self, x, y):
        self.x = x
        self.y = y

# Avec slots : ~80 bytes par instance
class PointOptimized:
    __slots__ = ['x', 'y']
    
    def __init__(self, x, y):
        self.x = x
        self.y = y
```

## Programmation asynchrone

### asyncio pour I/O-bound

```python
import asyncio
import aiohttp

# âŒ Synchrone : 10s pour 10 requÃªtes
import requests

def fetch_sync(url):
    response = requests.get(url)
    return response.text

urls = [f'https://api.example.com/{i}' for i in range(10)]
results = [fetch_sync(url) for url in urls]

# âœ… Asynchrone : ~1s pour 10 requÃªtes
async def fetch_async(session, url):
    async with session.get(url) as response:
        return await response.text()

async def fetch_all(urls):
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_async(session, url) for url in urls]
        return await asyncio.gather(*tasks)

results = asyncio.run(fetch_all(urls))
```

## ParallÃ©lisation

### multiprocessing pour CPU-bound

```python
from multiprocessing import Pool
import time

def cpu_intensive(n):
    """Calcul intensif"""
    return sum(i**2 for i in range(n))

numbers = [10000000] * 8

# SÃ©quentiel : ~8s
start = time.time()
results = [cpu_intensive(n) for n in numbers]
print(f"Sequential: {time.time() - start:.2f}s")

# ParallÃ¨le : ~2s sur 4 cores
start = time.time()
with Pool(4) as pool:
    results = pool.map(cpu_intensive, numbers)
print(f"Parallel: {time.time() - start:.2f}s")
```

### concurrent.futures

```python
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import requests

urls = ['https://example.com'] * 10

# ThreadPoolExecutor pour I/O
with ThreadPoolExecutor(max_workers=10) as executor:
    futures = [executor.submit(requests.get, url) for url in urls]
    results = [f.result() for f in futures]

# ProcessPoolExecutor pour CPU
def heavy_computation(n):
    return sum(i**2 for i in range(n))

with ProcessPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(heavy_computation, [10000000] * 8))
```

## Compilation JIT

### Numba pour calculs numÃ©riques

```python
import numpy as np
from numba import jit

# Sans Numba : ~2s
def monte_carlo_pi(n):
    inside = 0
    for i in range(n):
        x = np.random.random()
        y = np.random.random()
        if x*x + y*y <= 1:
            inside += 1
    return 4 * inside / n

# Avec Numba : ~0.1s
@jit(nopython=True)
def monte_carlo_pi_fast(n):
    inside = 0
    for i in range(n):
        x = np.random.random()
        y = np.random.random()
        if x*x + y*y <= 1:
            inside += 1
    return 4 * inside / n
```

## Caching

### functools.lru_cache

```python
from functools import lru_cache

# âŒ Lent : Recalcule Ã  chaque fois
def fibonacci(n):
    if n < 2:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# fibonacci(35) : ~3 secondes

# âœ… Rapide : Met en cache
@lru_cache(maxsize=None)
def fibonacci_cached(n):
    if n < 2:
        return n
    return fibonacci_cached(n-1) + fibonacci_cached(n-2)

# fibonacci_cached(35) : ~0.00001 secondes
```

## Optimisation base de donnÃ©es

### Utiliser des indexes

```sql
-- âŒ Lent : Scan complet
SELECT * FROM users WHERE email = 'user@example.com';

-- âœ… Rapide : Index
CREATE INDEX idx_users_email ON users(email);
```

### RequÃªtes en batch

```python
# âŒ Lent : N requÃªtes
for user_id in user_ids:
    user = db.query(User).filter(User.id == user_id).first()
    process(user)

# âœ… Rapide : 1 requÃªte
users = db.query(User).filter(User.id.in_(user_ids)).all()
for user in users:
    process(user)
```

### Pagination

```python
# âŒ Lent : Charge tout
users = db.query(User).all()

# âœ… Rapide : Pagine
users = db.query(User).limit(100).offset(page * 100).all()
```

## Bonnes pratiques

### âœ… Ã€ faire

1. **Profiler avant d'optimiser** : Mesurer le bottleneck rÃ©el
2. **Choisir la bonne structure** : dict/set pour recherches
3. **Utiliser les built-ins** : sum(), max(), sorted()
4. **GÃ©nÃ©rateurs pour grandes donnÃ©es** : yield au lieu de return []
5. **asyncio pour I/O** : RequÃªtes rÃ©seau, fichiers
6. **multiprocessing pour CPU** : Calculs lourds
7. **Caching intelligent** : lru_cache, Redis
8. **Indexes DB** : Pour les colonnes frÃ©quemment requÃªtÃ©es
9. **Batch operations** : Grouper les opÃ©rations
10. **Monitoring** : Surveiller les performances en prod

### âŒ Ã€ Ã©viter

1. **Optimisation prÃ©maturÃ©e** : Clarity first
2. **Micro-optimisations** : Optimiser 0.001% du temps
3. **Ignorer Big O** : O(nÂ²) sera toujours lent
4. **Caching excessif** : MÃ©moire limitÃ©e
5. **ParallÃ©lisation partout** : Overhead pour petites tÃ¢ches
6. **Oublier la lisibilitÃ©** : Code maintenable > rapide de 5%
7. **Ne pas profiler** : Optimiser au hasard
8. **Ignorer les dÃ©pendances** : API externe = bottleneck

## Contenu de cette section

### ğŸ“– Modules dÃ©taillÃ©s

1. **[Profiling et Analyse](42-01-profiling.md)**
   - cProfile, line_profiler
   - timeit, benchmarking
   - Visualisation des performances

2. **[Optimisation MÃ©moire](42-02-optimisation-memoire.md)**
   - memory_profiler
   - GÃ©nÃ©rateurs et itÃ©rateurs
   - Gestion efficace de la mÃ©moire

3. **[Asyncio et Concurrence](42-03-asyncio-et-concurrence.md)**
   - async/await
   - asyncio patterns
   - Threading vs Multiprocessing

## Checklist d'optimisation

```python
# Checklist avant d'optimiser
optimization_checklist = {
    'Profiling': [
        'â–¡ Identifier le bottleneck rÃ©el',
        'â–¡ Mesurer le temps actuel',
        'â–¡ DÃ©finir l'objectif de performance'
    ],
    'Algorithme': [
        'â–¡ VÃ©rifier la complexitÃ© (Big O)',
        'â–¡ Utiliser la bonne structure de donnÃ©es',
        'â–¡ Exploiter les built-ins Python'
    ],
    'DonnÃ©es': [
        'â–¡ Utiliser des gÃ©nÃ©rateurs si possible',
        'â–¡ Ã‰viter les copies inutiles',
        'â–¡ LibÃ©rer la mÃ©moire non utilisÃ©e'
    ],
    'I/O': [
        'â–¡ Utiliser asyncio pour I/O-bound',
        'â–¡ Batching des opÃ©rations DB',
        'â–¡ Caching des rÃ©sultats coÃ»teux'
    ],
    'CPU': [
        'â–¡ multiprocessing pour CPU-bound',
        'â–¡ Numba pour calculs numÃ©riques',
        'â–¡ Cython pour code critique'
    ],
    'Validation': [
        'â–¡ Mesurer l'amÃ©lioration',
        'â–¡ Tester la correction',
        'â–¡ VÃ©rifier la lisibilitÃ©'
    ]
}
```

## Ordre d'optimisation recommandÃ©

```
1. Algorithme        â†’ Gain potentiel : 100x-1000x
   â†“
2. Structure donnÃ©es â†’ Gain potentiel : 10x-100x
   â†“
3. Caching          â†’ Gain potentiel : 10x-100x
   â†“
4. DB optimization  â†’ Gain potentiel : 10x-50x
   â†“
5. Asyncio          â†’ Gain potentiel : 5x-20x
   â†“
6. Multiprocessing  â†’ Gain potentiel : 2x-8x
   â†“
7. Micro-opt        â†’ Gain potentiel : 1.1x-2x
```

## Ressources

- **High Performance Python** : Micha Gorelick & Ian Ozsvald
- **Python Performance** : https://wiki.python.org/moin/PythonSpeed
- **Profiling Guide** : https://docs.python.org/3/library/profile.html
- **asyncio docs** : https://docs.python.org/3/library/asyncio.html
- **Numba** : https://numba.pydata.org/

## Conclusion

L'optimisation est un Ã©quilibre entre :
- âš¡ Performance
- ğŸ“– LisibilitÃ©
- ğŸ”§ MaintenabilitÃ©
- â±ï¸ Temps de dÃ©veloppement

**"Make it work, make it right, make it fast - in that order"** - Kent BeckLa performance compte, mais un code clair et correct compte plus. Optimisez quand c'est nÃ©cessaire, lÃ  oÃ¹ c'est nÃ©cessaire, aprÃ¨s avoir mesurÃ©.
