---
title: "Tests et QualitÃ© de Code"
order: 41
parent: null
tags: ["python", "tests", "quality", "pytest", "unittest"]
---

# Tests et QualitÃ© de Code

## Introduction

Les tests sont essentiels pour garantir la qualitÃ©, la fiabilitÃ© et la maintenabilitÃ© du code. Un code bien testÃ© est plus facile Ã  refactorer, Ã  faire Ã©voluer et donne confiance lors des dÃ©ploiements.

### Pourquoi tester ?

| Avantage | Description |
|----------|-------------|
| **Confiance** | DÃ©ployer sans crainte de casser quelque chose |
| **Documentation** | Les tests documentent le comportement attendu |
| **Refactoring** | Modifier le code en toute sÃ©curitÃ© |
| **QualitÃ©** | DÃ©tecter les bugs tÃ´t dans le cycle |
| **Design** | Encourage un meilleur design (testable = modulaire) |
| **RÃ©gression** | Ã‰viter que les bugs corrigÃ©s ne reviennent |

### La pyramide des tests

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     E2E     â”‚  â† Peu nombreux, lents
                    â”‚   (UI/API)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   INTÃ‰GRATION     â”‚  â† Moyennement nombreux
                  â”‚  (Composants)     â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚      TESTS UNITAIRES        â”‚  â† Nombreux, rapides
              â”‚       (Fonctions)           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Principe** : Plus on monte dans la pyramide, moins on a de tests (mais plus ils sont complets).

### Types de tests

| Type | Scope | Vitesse | QuantitÃ© |
|------|-------|---------|----------|
| **Unitaires** | Fonction/MÃ©thode | TrÃ¨s rapide | 70% |
| **IntÃ©gration** | Plusieurs composants | Moyen | 20% |
| **E2E** | Application complÃ¨te | Lent | 10% |
| **Performance** | Benchmarks | Variable | Ad-hoc |
| **SÃ©curitÃ©** | VulnÃ©rabilitÃ©s | Moyen | Ad-hoc |

## Frameworks de tests Python

### pytest (RecommandÃ©)

Le framework le plus populaire et moderne.

```python
# test_example.py
def add(a, b):
    return a + b

def test_add():
    assert add(2, 3) == 5
    assert add(-1, 1) == 0
    assert add(0, 0) == 0
```

**Avantages** :
- âœ… Syntaxe simple (assert natif)
- âœ… Fixtures puissantes
- âœ… Plugins nombreux
- âœ… DÃ©couverte automatique des tests
- âœ… Rapports dÃ©taillÃ©s

### unittest (Standard Library)

Framework intÃ©grÃ© Ã  Python.

```python
# test_example.py
import unittest

class TestMath(unittest.TestCase):
    def test_add(self):
        self.assertEqual(2 + 3, 5)
    
    def test_subtract(self):
        self.assertEqual(5 - 3, 2)

if __name__ == '__main__':
    unittest.main()
```

**Avantages** :
- âœ… Pas de dÃ©pendance externe
- âœ… Style xUnit familier
- âœ… Bien documentÃ©

### Autres frameworks

| Framework | Usage |
|-----------|-------|
| **doctest** | Tests dans les docstrings |
| **nose2** | Extension de unittest |
| **hypothesis** | Property-based testing |
| **Robot Framework** | Tests d'acceptation |

## Concepts clÃ©s

### Test-Driven Development (TDD)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CYCLE TDD                          â”‚
â”‚                                                 â”‚
â”‚   1. RED    â†’   2. GREEN   â†’   3. REFACTOR    â”‚
â”‚   Ã‰crire       Faire          AmÃ©liorer        â”‚
â”‚   un test      passer         le code          â”‚
â”‚   qui Ã©choue   le test                         â”‚
â”‚                                                 â”‚
â”‚        â†“            â†“              â†“            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                    â†“                            â”‚
â”‚                 RÃ‰PÃ‰TER                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemple TDD** :

```python
# 1. RED - Ã‰crire le test d'abord
def test_calculate_discount():
    assert calculate_discount(100, 10) == 90
    assert calculate_discount(50, 20) == 40

# 2. GREEN - ImplÃ©menter le minimum
def calculate_discount(price, discount_percent):
    return price - (price * discount_percent / 100)

# 3. REFACTOR - AmÃ©liorer
def calculate_discount(price, discount_percent):
    """Calcule le prix aprÃ¨s rÃ©duction"""
    if not 0 <= discount_percent <= 100:
        raise ValueError("Discount must be between 0 and 100")
    return price * (1 - discount_percent / 100)
```

### Arrange-Act-Assert (AAA)

Pattern pour structurer les tests :

```python
def test_user_registration():
    # ARRANGE - PrÃ©parer les donnÃ©es
    username = "john_doe"
    email = "john@example.com"
    
    # ACT - ExÃ©cuter l'action
    user = register_user(username, email)
    
    # ASSERT - VÃ©rifier le rÃ©sultat
    assert user.username == username
    assert user.email == email
    assert user.is_active is True
```

### Fixtures

PrÃ©parer l'environnement de test :

```python
import pytest

@pytest.fixture
def database():
    """Fixture pour crÃ©er une DB de test"""
    db = create_test_database()
    yield db  # Fournir la DB aux tests
    db.cleanup()  # Nettoyer aprÃ¨s les tests

def test_user_creation(database):
    user = database.create_user("john")
    assert user.name == "john"
```

### Mocking

Simuler des dÃ©pendances externes :

```python
from unittest.mock import Mock, patch

def test_send_email():
    # Mock du service email
    with patch('myapp.email.send') as mock_send:
        mock_send.return_value = True
        
        result = send_welcome_email("user@example.com")
        
        assert result is True
        mock_send.assert_called_once_with("user@example.com", "Welcome!")
```

## Couverture de code

### Mesurer la couverture

```bash
# Installer pytest-cov
pip install pytest-cov

# Lancer les tests avec couverture
pytest --cov=myapp tests/

# GÃ©nÃ©rer un rapport HTML
pytest --cov=myapp --cov-report=html tests/

# Rapport dÃ©taillÃ©
pytest --cov=myapp --cov-report=term-missing tests/
```

### InterprÃ©ter la couverture

```
Name                Stmts   Miss  Cover   Missing
-------------------------------------------------
myapp/__init__.py       4      0   100%
myapp/models.py        45      5    89%   23-27
myapp/views.py         67     12    82%   45, 67-78
myapp/utils.py         23      0   100%
-------------------------------------------------
TOTAL                 139     17    88%
```

**Objectifs** :
- ğŸ¯ **80%+** : Bon niveau de couverture
- ğŸ¯ **90%+** : Excellent niveau
- âš ï¸ **100%** : Pas toujours nÃ©cessaire (coÃ»t/bÃ©nÃ©fice)

### Configuration coverage

```ini
# .coveragerc
[run]
source = myapp
omit = 
    */tests/*
    */venv/*
    */__pycache__/*

[report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
```

## QualitÃ© de code

### Linters

**flake8** : VÃ©rification de style

```bash
pip install flake8
flake8 myapp/

# Configuration
# .flake8
[flake8]
max-line-length = 100
exclude = .git,__pycache__,venv
ignore = E203,W503
```

**pylint** : Analyse statique avancÃ©e

```bash
pip install pylint
pylint myapp/

# Configuration
# .pylintrc
[MASTER]
max-line-length=100

[MESSAGES CONTROL]
disable=C0111,R0903
```

**mypy** : VÃ©rification des types

```bash
pip install mypy
mypy myapp/

# mypy.ini
[mypy]
python_version = 3.11
warn_return_any = True
warn_unused_configs = True
disallow_untyped_defs = True
```

### Formatters

**black** : Formatage automatique

```bash
pip install black
black myapp/

# pyproject.toml
[tool.black]
line-length = 100
target-version = ['py311']
```

**isort** : Tri des imports

```bash
pip install isort
isort myapp/

# .isort.cfg
[settings]
profile = black
line_length = 100
```

### Pre-commit hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.12.0
    hooks:
      - id: black

  - repo: https://github.com/pycqa/isort
    rev: 5.13.0
    hooks:
      - id: isort

  - repo: https://github.com/pycqa/flake8
    rev: 7.0.0
    hooks:
      - id: flake8

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.7.1
    hooks:
      - id: mypy
```

```bash
# Installation
pip install pre-commit
pre-commit install

# ExÃ©cution manuelle
pre-commit run --all-files
```

## Organisation des tests

### Structure recommandÃ©e

```
mon_projet/
â”‚
â”œâ”€â”€ myapp/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ views.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py          # Fixtures partagÃ©es
â”‚   â”‚
â”‚   â”œâ”€â”€ unit/                # Tests unitaires
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_models.py
â”‚   â”‚   â”œâ”€â”€ test_views.py
â”‚   â”‚   â””â”€â”€ test_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/         # Tests d'intÃ©gration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_api.py
â”‚   â”‚   â””â”€â”€ test_database.py
â”‚   â”‚
â”‚   â””â”€â”€ e2e/                 # Tests end-to-end
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_user_flow.py
â”‚
â”œâ”€â”€ pytest.ini               # Configuration pytest
â”œâ”€â”€ .coveragerc             # Configuration coverage
â””â”€â”€ requirements-dev.txt    # DÃ©pendances de test
```

### Conventions de nommage

```python
# Fichiers de test
test_*.py  ou  *_test.py

# Fonctions de test
def test_function_name():
    pass

# Classes de test
class TestClassName:
    def test_method_name(self):
        pass

# Fixtures
@pytest.fixture
def fixture_name():
    pass
```

## Continuous Testing

### Configuration pytest.ini

```ini
# pytest.ini
[pytest]
minversion = 6.0
addopts = 
    -ra
    -q
    --strict-markers
    --cov=myapp
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=80
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
markers =
    slow: marks tests as slow
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    smoke: marks tests as smoke tests
```

### ExÃ©cution sÃ©lective

```bash
# Tous les tests
pytest

# Tests d'un fichier
pytest tests/test_models.py

# Tests d'une classe
pytest tests/test_models.py::TestUser

# Tests d'une fonction
pytest tests/test_models.py::test_user_creation

# Tests par marker
pytest -m unit
pytest -m "not slow"
pytest -m "integration or e2e"

# Tests par nom
pytest -k "user"
pytest -k "not slow"

# Verbose
pytest -v

# ArrÃªter au premier Ã©chec
pytest -x

# Mode parallÃ¨le
pytest -n auto
```

## Bonnes pratiques

### âœ… Ã€ faire

1. **Tests indÃ©pendants** : Chaque test doit pouvoir s'exÃ©cuter seul
2. **Tests dÃ©terministes** : MÃªme input = mÃªme output
3. **Tests rapides** : Les tests unitaires doivent Ãªtre trÃ¨s rapides
4. **Noms explicites** : `test_user_cannot_login_with_wrong_password()`
5. **Un concept par test** : Tester une seule chose Ã  la fois
6. **Arrange-Act-Assert** : Structurer clairement les tests
7. **Fixtures rÃ©utilisables** : DRY pour la prÃ©paration des tests
8. **Coverage significatif** : Tester les cas limites et erreurs
9. **Tests dans le CI** : Automatiser l'exÃ©cution
10. **Documentation** : Commenter les tests complexes

### âŒ Ã€ Ã©viter

1. **Tests dÃ©pendants** : Un test ne doit pas dÃ©pendre d'un autre
2. **Tests flaky** : Tests qui Ã©chouent alÃ©atoirement
3. **Tests trop lents** : Optimiser ou marquer comme `@slow`
4. **Tester l'implÃ©mentation** : Tester le comportement, pas le code
5. **Ignorer les tests qui Ã©chouent** : Corriger ou supprimer
6. **Pas de tests pour les bugs** : Toujours ajouter un test de rÃ©gression
7. **Mocking excessif** : Ne pas tout mocker
8. **Tests incomprÃ©hensibles** : ClartÃ© avant concision
9. **Duplication** : Utiliser des fixtures et helpers
10. **Oublier les cas limites** : Tester les erreurs et edge cases

## Contenu de cette section

Cette section couvre tous les aspects des tests en Python :

### ğŸ“– Modules thÃ©oriques

1. **[Pytest - Framework de Tests](41-01-pytest.md)**
   - Installation et configuration
   - Fixtures et parametrize
   - Plugins essentiels
   - Mocking et patching

2. **[Tests Unitaires](41-02-tests-unitaires.md)**
   - Principes des tests unitaires
   - TDD en pratique
   - Tester diffÃ©rents types de code
   - Exemples complets

3. **[Tests d'IntÃ©gration](41-03-tests-d-integration.md)**
   - Tests avec base de donnÃ©es
   - Tests d'API
   - Tests avec dÃ©pendances externes
   - Docker pour les tests

## Parcours recommandÃ©

### Niveau 1 : Fondations (1 semaine)
- Comprendre les types de tests
- Ã‰crire des tests simples avec pytest
- Mesurer la couverture de code
- Configurer les linters

### Niveau 2 : IntermÃ©diaire (2 semaines)
- MaÃ®triser les fixtures pytest
- Pratiquer le TDD
- Tests d'intÃ©gration avec DB
- Mocking avancÃ©

### Niveau 3 : AvancÃ© (2 semaines)
- Tests de performance
- Property-based testing
- Tests E2E
- CI/CD avec tests automatisÃ©s

## MÃ©triques de qualitÃ©

### Code Quality Score

```python
# Calculer un score de qualitÃ©
def calculate_quality_score():
    metrics = {
        'coverage': 85,        # % de couverture
        'pylint': 9.2,        # Score pylint (0-10)
        'complexity': 3.5,    # ComplexitÃ© cyclomatique moyenne
        'duplicates': 2,      # % de code dupliquÃ©
        'violations': 5       # Nombre de violations
    }
    
    score = (
        metrics['coverage'] * 0.3 +
        metrics['pylint'] * 10 * 0.3 +
        (10 - metrics['complexity']) * 10 * 0.2 +
        (100 - metrics['duplicates']) * 0.1 +
        max(0, 100 - metrics['violations'] * 2) * 0.1
    )
    
    return round(score, 2)
```

### Objectifs

| MÃ©trique | Objectif | Excellent |
|----------|----------|-----------|
| **Coverage** | 80% | 90%+ |
| **Pylint** | 8.0 | 9.5+ |
| **Complexity** | < 10 | < 5 |
| **Duplicates** | < 5% | < 2% |
| **Build time** | < 5min | < 2min |

## Outils complÃ©mentaires

### Analyse de code

```bash
# ComplexitÃ© cyclomatique
pip install radon
radon cc myapp/ -a

# Duplication de code
pip install pylint
pylint --disable=all --enable=duplicate-code myapp/

# SÃ©curitÃ©
pip install bandit
bandit -r myapp/

# DÃ©pendances vulnÃ©rables
pip install safety
safety check
```

### Documentation

```bash
# GÃ©nÃ©rer la documentation
pip install sphinx
sphinx-quickstart
sphinx-build -b html docs/ docs/_build/

# Docstring coverage
pip install interrogate
interrogate myapp/
```

## Ressources

- **pytest** : https://docs.pytest.org
- **unittest** : https://docs.python.org/3/library/unittest.html
- **Coverage.py** : https://coverage.readthedocs.io
- **Test Driven Development** : Kent Beck
- **Clean Code** : Robert C. Martin
- **Working Effectively with Legacy Code** : Michael Feathers

## Conclusion

Les tests et la qualitÃ© de code ne sont pas optionnels pour du code professionnel. Ils sont un investissement qui se rentabilise rapidement en :
- ğŸš€ RÃ©duisant les bugs en production
- ğŸ’° Diminuant le temps de debugging
- ğŸ”„ Facilitant le refactoring
- ğŸ“ˆ AmÃ©liorant la maintenabilitÃ©
- ğŸ˜Œ Augmentant la confiance de l'Ã©quipe**"Code without tests is broken by design"** - Jacob Kaplan-Moss
