---
title: "Exercices et Projets - Intelligence Artificielle"
order: 26
parent: "20-ia-introduction.md"
tags: ["python", "exercices", "ia", "projects", "llm", "qdrant"]
---

# Exercices et Projets - Intelligence Artificielle

## Pr√©paration

Avant de commencer, installez les d√©pendances :

```bash
pip install openai sentence-transformers qdrant-client numpy scikit-learn
```

Cr√©ez un fichier `.env` avec vos cl√©s API :

```bash
OPENAI_API_KEY=votre-cl√©-openai
```

## Exercices LLM

### Exercice 1 : Premier chatbot avec OpenAI

**Objectif** : Cr√©er un chatbot simple qui r√©pond aux questions.

**Instructions** :
1. Cr√©ez une classe `ChatbotSimple` qui utilise l'API OpenAI
2. Le chatbot doit garder un historique de conversation
3. Impl√©mentez une m√©thode `repondre(question)` qui retourne la r√©ponse

**Solution de base** :

```python
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

class ChatbotSimple:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.historique = []
    
    def repondre(self, question):
        # Ajouter la question √† l'historique
        self.historique.append({"role": "user", "content": question})
        
        # Appeler l'API
        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Tu es un assistant Python utile."},
                *self.historique
            ]
        )
        
        reponse = response.choices[0].message.content
        self.historique.append({"role": "assistant", "content": reponse})
        
        return reponse

# Test
chatbot = ChatbotSimple()
print(chatbot.repondre("Qu'est-ce qu'une fonction lambda en Python ?"))
print(chatbot.repondre("Peux-tu me donner un exemple ?"))
```

**Am√©liorations √† ajouter** :
- Limiter la taille de l'historique (garder seulement les 10 derniers messages)
- Gestion des erreurs (RateLimitError, etc.)
- Format de sortie plus joli

### Exercice 2 : G√©n√©rateur de contenu avec prompts

**Objectif** : Cr√©er un g√©n√©rateur de contenu qui utilise diff√©rents templates de prompts.

**Instructions** :
1. Cr√©ez une classe `GenerateurContenu` avec diff√©rents types de g√©n√©ration
2. Impl√©mentez des m√©thodes pour :
   - G√©n√©rer un article
   - G√©n√©rer un r√©sum√©
   - G√©n√©rer des id√©es cr√©atives

**Solution de base** :

```python
class GenerateurContenu:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    def generer_article(self, sujet, style="professionnel", longueur=500):
        prompt = f"""
        √âcris un article sur le sujet suivant :
        
        Sujet: {sujet}
        Style: {style}
        Longueur: {longueur} mots
        
        L'article doit avoir une introduction, un d√©veloppement et une conclusion.
        """
        
        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8,
            max_tokens=longueur * 2
        )
        
        return response.choices[0].message.content
    
    def generer_resume(self, texte):
        prompt = f"""
        R√©sume ce texte en 3-5 phrases cl√©s :
        
        {texte}
        """
        
        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=150
        )
        
        return response.choices[0].message.content
    
    def generer_idees(self, sujet, nombre=5):
        prompt = f"""
        G√©n√®re {nombre} id√©es cr√©atives sur le sujet suivant :
        
        Sujet: {sujet}
        
        Format: Liste num√©rot√©e avec une phrase par id√©e.
        """
        
        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=1.2,
            max_tokens=200
        )
        
        return response.choices[0].message.content

# Test
generateur = GenerateurContenu()
print(generateur.generer_article("L'intelligence artificielle", "professionnel", 300))
print(generateur.generer_idees("Applications de l'IA", 3))
```

### Exercice 3 : Fine-tuning de prompts

**Objectif** : Cr√©er un syst√®me qui teste et optimise diff√©rents prompts.

**Instructions** :
1. Cr√©ez une fonction qui teste plusieurs variations de prompts
2. Comparez les r√©sultats et identifiez le meilleur prompt
3. Impl√©mentez un syst√®me de scoring pour √©valuer les r√©ponses

**Solution de base** :

```python
def tester_prompts(question, prompts):
    """Teste plusieurs prompts et retourne les r√©sultats"""
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    resultats = []
    
    for i, prompt_template in enumerate(prompts):
        prompt = prompt_template.format(question=question)
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        
        resultats.append({
            "prompt_num": i + 1,
            "prompt": prompt_template,
            "reponse": response.choices[0].message.content,
            "tokens": response.usage.total_tokens
        })
    
    return resultats

# Test avec diff√©rents prompts
question = "Explique-moi les listes Python"
prompts = [
    "Explique {question}",
    "Tu es un expert Python. Explique {question} de mani√®re claire.",
    "Explique {question} avec un exemple de code pratique."
]

resultats = tester_prompts(question, prompts)
for r in resultats:
    print(f"\nPrompt {r['prompt_num']}:")
    print(f"Tokens: {r['tokens']}")
    print(f"R√©ponse: {r['reponse'][:100]}...")
```

## Exercices Embeddings

### Exercice 1 : G√©n√©ration d'embeddings de texte

**Objectif** : Cr√©er un syst√®me qui g√©n√®re des embeddings pour des textes.

**Instructions** :
1. Utilisez Sentence Transformers pour g√©n√©rer des embeddings
2. Cr√©ez une fonction qui calcule la similarit√© entre deux textes
3. Visualisez les embeddings (optionnel avec PCA)

**Solution** :

```python
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class GenerateurEmbeddings:
    def __init__(self):
        self.model = SentenceTransformer('paraphrase-MiniLM-L6-v2')
    
    def generer_embedding(self, texte):
        """G√©n√®re un embedding pour un texte"""
        return self.model.encode(texte)
    
    def similarite(self, texte1, texte2):
        """Calcule la similarit√© entre deux textes"""
        emb1 = self.generer_embedding(texte1)
        emb2 = self.generer_embedding(texte2)
        
        return cosine_similarity([emb1], [emb2])[0][0]
    
    def textes_similaires(self, texte_reference, textes, top_k=3):
        """Trouve les textes les plus similaires"""
        emb_ref = self.generer_embedding(texte_reference)
        embs = self.model.encode(textes)
        
        similarites = cosine_similarity([emb_ref], embs)[0]
        indices = np.argsort(similarites)[::-1][:top_k]
        
        return [
            {"texte": textes[i], "score": float(similarites[i])}
            for i in indices
        ]

# Test
generateur = GenerateurEmbeddings()

textes = [
    "Python est un langage de programmation",
    "Les listes Python sont mutables",
    "Le chat est un animal",
    "Les fonctions Python peuvent retourner plusieurs valeurs"
]

resultats = generateur.textes_similaires(
    "Comment utiliser Python ?",
    textes,
    top_k=2
)

for r in resultats:
    print(f"Score: {r['score']:.2f} - {r['texte']}")
```

### Exercice 2 : Recherche s√©mantique simple

**Objectif** : Cr√©er un syst√®me de recherche s√©mantique.

**Instructions** :
1. Cr√©ez une classe `RechercheSemantique` qui indexe des documents
2. Impl√©mentez une m√©thode de recherche qui trouve les documents les plus pertinents
3. Affichez les r√©sultats avec leurs scores de similarit√©

**Solution** :

```python
class RechercheSemantique:
    def __init__(self, documents):
        self.model = SentenceTransformer('paraphrase-MiniLM-L6-v2')
        self.documents = documents
        self.embeddings = self.model.encode(documents)
    
    def rechercher(self, requete, top_k=5):
        """Recherche les documents les plus pertinents"""
        emb_requete = self.model.encode([requete])
        similarites = cosine_similarity(emb_requete, self.embeddings)[0]
        
        indices = np.argsort(similarites)[::-1][:top_k]
        
        return [
            {
                "document": self.documents[i],
                "score": float(similarites[i]),
                "index": i
            }
            for i in indices
        ]

# Test
documents = [
    "Python est un langage de programmation interpr√©t√©",
    "Les listes Python sont des structures de donn√©es mutables",
    "Les fonctions Python peuvent retourner plusieurs valeurs",
    "Le chat est un animal domestique",
    "Les d√©corateurs Python modifient le comportement des fonctions"
]

recherche = RechercheSemantique(documents)
resultats = recherche.rechercher("Comment utiliser les fonctions Python ?", top_k=3)

for r in resultats:
    print(f"\nScore: {r['score']:.3f}")
    print(f"Document: {r['document']}")
```

## Exercices Qdrant

### Exercice 1 : Cr√©ation d'une collection vectorielle

**Objectif** : Cr√©er et peupler une collection Qdrant.

**Instructions** :
1. D√©marrez Qdrant (Docker ou local)
2. Cr√©ez une collection avec des embeddings de 384 dimensions
3. Ajoutez au moins 5 documents avec leurs embeddings

**Solution** :

```python
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from sentence_transformers import SentenceTransformer

# Connexion
client = QdrantClient(host="localhost", port=6333)
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Cr√©er la collection
collection_name = "exercice_collection"
try:
    client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(
            size=384,
            distance=Distance.COSINE
        )
    )
    print(f"Collection '{collection_name}' cr√©√©e")
except Exception as e:
    print(f"Collection existe d√©j√† ou erreur: {e}")

# Documents √† indexer
documents = [
    {"id": 1, "texte": "Python est un langage de programmation"},
    {"id": 2, "texte": "Les listes Python sont mutables"},
    {"id": 3, "texte": "Les fonctions Python peuvent retourner plusieurs valeurs"},
    {"id": 4, "texte": "Les d√©corateurs Python modifient les fonctions"},
    {"id": 5, "texte": "Le chat est un animal domestique"}
]

# G√©n√©rer les embeddings et cr√©er les points
points = []
for doc in documents:
    embedding = model.encode(doc["texte"]).tolist()
    point = PointStruct(
        id=doc["id"],
        vector=embedding,
        payload={"texte": doc["texte"]}
    )
    points.append(point)

# Ajouter √† Qdrant
client.upsert(collection_name=collection_name, points=points)
print(f"{len(points)} points ajout√©s √† la collection")
```

### Exercice 2 : Recherche par similarit√©

**Objectif** : Impl√©menter une recherche par similarit√© dans Qdrant.

**Instructions** :
1. Utilisez la collection cr√©√©e pr√©c√©demment
2. Cr√©ez une fonction de recherche qui prend une requ√™te et retourne les documents similaires
3. Affichez les r√©sultats avec leurs scores

**Solution** :

```python
def rechercher_similarite(requete, top_k=3):
    """Recherche des documents similaires"""
    # G√©n√©rer l'embedding de la requ√™te
    embedding = model.encode(requete).tolist()
    
    # Rechercher dans Qdrant
    resultats = client.search(
        collection_name=collection_name,
        query_vector=embedding,
        limit=top_k
    )
    
    return resultats

# Test
requete = "Comment utiliser Python ?"
resultats = rechercher_similarite(requete, top_k=3)

print(f"R√©sultats pour: '{requete}'\n")
for i, resultat in enumerate(resultats, 1):
    print(f"{i}. Score: {resultat.score:.3f}")
    print(f"   Texte: {resultat.payload['texte']}\n")
```

### Exercice 3 : Filtrage avec m√©tadonn√©es

**Objectif** : Ajouter des m√©tadonn√©es et filtrer les recherches.

**Instructions** :
1. Ajoutez des m√©tadonn√©es (cat√©gorie, date, etc.) aux documents
2. Impl√©mentez une recherche avec filtre sur les m√©tadonn√©es
3. Testez avec diff√©rents filtres

**Solution** :

```python
from qdrant_client.models import Filter, FieldCondition, MatchValue

# Ajouter des documents avec m√©tadonn√©es
documents_avec_meta = [
    {"id": 6, "texte": "Introduction √† Python", "categorie": "d√©butant", "niveau": 1},
    {"id": 7, "texte": "Les d√©corateurs avanc√©s", "categorie": "avanc√©", "niveau": 3},
    {"id": 8, "texte": "Les bases de Python", "categorie": "d√©butant", "niveau": 1}
]

points_meta = []
for doc in documents_avec_meta:
    embedding = model.encode(doc["texte"]).tolist()
    point = PointStruct(
        id=doc["id"],
        vector=embedding,
        payload={
            "texte": doc["texte"],
            "categorie": doc["categorie"],
            "niveau": doc["niveau"]
        }
    )
    points_meta.append(point)

client.upsert(collection_name=collection_name, points=points_meta)

# Recherche avec filtre
def rechercher_avec_filtre(requete, categorie=None, top_k=3):
    """Recherche avec filtre sur les m√©tadonn√©es"""
    embedding = model.encode(requete).tolist()
    
    # Construire le filtre
    query_filter = None
    if categorie:
        query_filter = Filter(
            must=[
                FieldCondition(
                    key="categorie",
                    match=MatchValue(value=categorie)
                )
            ]
        )
    
    resultats = client.search(
        collection_name=collection_name,
        query_vector=embedding,
        query_filter=query_filter,
        limit=top_k
    )
    
    return resultats

# Test avec filtre
resultats = rechercher_avec_filtre("Apprendre Python", categorie="d√©butant")
print("R√©sultats filtr√©s (cat√©gorie: d√©butant):")
for r in resultats:
    print(f"- {r.payload['texte']} (score: {r.score:.3f})")
```

## Projets complets

### Projet 1 : Assistant IA personnalis√©

**Objectif** : Cr√©er un assistant IA complet avec m√©moire et personnalisation.

**Fonctionnalit√©s √† impl√©menter** :
- Conversation avec historique
- Personnalisation du comportement
- Gestion des erreurs
- Export de la conversation

**Structure sugg√©r√©e** :

```python
class AssistantPersonnalise:
    def __init__(self, personnalite="utile"):
        # Initialisation
        pass
    
    def definir_personnalite(self, description):
        # D√©finir la personnalit√©
        pass
    
    def converser(self, message):
        # Conversation avec historique
        pass
    
    def exporter_conversation(self, fichier):
        # Exporter l'historique
        pass
```

### Projet 2 : Syst√®me de recommandation bas√© sur embeddings

**Objectif** : Cr√©er un syst√®me qui recommande du contenu similaire.

**Fonctionnalit√©s** :
- Indexation de contenu
- Recommandations bas√©es sur la similarit√©
- Interface simple (CLI ou web)

### Projet 3 : Chatbot avec m√©moire (RAG)

**Objectif** : Cr√©er un chatbot RAG complet.

**Fonctionnalit√©s** :
- Indexation de documents
- Recherche de contexte
- G√©n√©ration de r√©ponses avec contexte
- Affichage des sources

**Structure sugg√©r√©e** :

```python
class ChatbotRAG:
    def __init__(self):
        # Initialiser Qdrant, embeddings, LLM
        pass
    
    def indexer_documents(self, documents):
        # Indexer des documents
        pass
    
    def poser_question(self, question):
        # Rechercher contexte + g√©n√©rer r√©ponse
        pass
```

## Conseils pour les projets

1. **Commencez simple** : Impl√©mentez d'abord les fonctionnalit√©s de base
2. **Testez r√©guli√®rement** : Testez chaque fonctionnalit√© au fur et √† mesure
3. **G√©rez les erreurs** : Ajoutez la gestion d'erreurs d√®s le d√©but
4. **Documentez** : Commentez votre code
5. **It√©rez** : Am√©liorez progressivement

## Ressources suppl√©mentaires

- **Documentation OpenAI** : https://platform.openai.com/docs
- **Sentence Transformers** : https://www.sbert.net
- **Qdrant** : https://qdrant.tech/documentation
- **Exemples GitHub** : Recherchez des projets RAG sur GitHub

Bon courage avec vos exercices ! üöÄ
