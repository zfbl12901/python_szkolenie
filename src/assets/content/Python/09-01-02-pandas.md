---
title: "Pandas"
order: 9.01.02
parent: "09-01-data-manipulation.md"
tags: ["python", "pandas", "dataframe", "analyse"]
---

# Pandas

Pandas est la bibliothèque de référence pour la manipulation et l'analyse de données structurées en Python. Elle fournit des structures de données puissantes et des outils d'analyse.

## Concepts de base

**Pandas** fournit deux structures principales :
- **Series** : Tableau unidimensionnel avec index
- **DataFrame** : Tableau bidimensionnel (comme une feuille Excel)

### Pourquoi Pandas ?

- **Manipulation facile** : Opérations sur données tabulaires
- **Performance** : Basé sur NumPy, optimisé
- **Fonctionnalités** : Lecture/écriture, groupby, merge, pivot
- **Intégration** : Compatible avec NumPy, matplotlib, etc.

## Installation et import

### Installation

```bash
# Installer Pandas
pip install pandas

# Ou avec Poetry
poetry add pandas
```

### Import conventionnel

```python
import pandas as pd
import numpy as np
```

## Series et DataFrame

### Series

```python
import pandas as pd

# Créer une Series
s = pd.Series([1, 2, 3, 4, 5])
print(s)
# 0    1
# 1    2
# 2    3
# 3    4
# 4    5
# dtype: int64

# Avec index personnalisé
s = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'])
print(s['a'])  # 1

# Depuis un dictionnaire
s = pd.Series({'a': 1, 'b': 2, 'c': 3})
```

### DataFrame

```python
# Créer un DataFrame
data = {
    'nom': ['Alice', 'Bob', 'Charlie'],
    'âge': [25, 30, 35],
    'ville': ['Paris', 'Lyon', 'Marseille']
}
df = pd.DataFrame(data)
print(df)
#       nom  âge      ville
# 0   Alice   25      Paris
# 1     Bob   30       Lyon
# 2 Charlie   35  Marseille

# Avec index personnalisé
df = pd.DataFrame(data, index=['a', 'b', 'c'])

# Depuis une liste de dictionnaires
data = [
    {'nom': 'Alice', 'âge': 25},
    {'nom': 'Bob', 'âge': 30}
]
df = pd.DataFrame(data)
```

### Propriétés de base

```python
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6]
})

print(df.shape)        # (3, 2) - dimensions
print(df.size)         # 6 - nombre total d'éléments
print(df.columns)      # Index(['A', 'B'])
print(df.index)        # RangeIndex(start=0, stop=3, step=1)
print(df.dtypes)       # Types de chaque colonne
print(df.info())       # Informations détaillées
print(df.describe())   # Statistiques descriptives
```

## Lecture et écriture de données

### Lecture de fichiers

```python
# CSV
df = pd.read_csv('data.csv')

# Avec options
df = pd.read_csv('data.csv', 
                 sep=',',
                 header=0,
                 index_col=0,
                 encoding='utf-8')

# Excel
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')

# JSON
df = pd.read_json('data.json')

# Parquet (format efficace)
df = pd.read_parquet('data.parquet')

# SQL
import sqlite3
conn = sqlite3.connect('database.db')
df = pd.read_sql_query('SELECT * FROM users', conn)
```

### Écriture de fichiers

```python
# CSV
df.to_csv('output.csv', index=False)

# Excel
df.to_excel('output.xlsx', sheet_name='Data', index=False)

# JSON
df.to_json('output.json', orient='records')

# Parquet
df.to_parquet('output.parquet')

# SQL
df.to_sql('table_name', conn, if_exists='replace', index=False)
```

## Sélection et filtrage

### Sélection de colonnes

```python
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6],
    'C': [7, 8, 9]
})

# Une colonne (retourne une Series)
col_a = df['A']

# Plusieurs colonnes (retourne un DataFrame)
cols = df[['A', 'B']]

# Avec loc (label-based)
col_a = df.loc[:, 'A']

# Avec iloc (integer-based)
col_a = df.iloc[:, 0]
```

### Sélection de lignes

```python
# Par index
row = df.loc[0]  # Première ligne
rows = df.loc[0:2]  # Lignes 0 à 2

# Par position
row = df.iloc[0]  # Première ligne
rows = df.iloc[0:3]  # Lignes 0, 1, 2

# Par condition
filtered = df[df['A'] > 1]

# Conditions multiples
filtered = df[(df['A'] > 1) & (df['B'] < 6)]
```

### Filtrage avancé

```python
df = pd.DataFrame({
    'nom': ['Alice', 'Bob', 'Charlie', 'David'],
    'âge': [25, 30, 35, 40],
    'ville': ['Paris', 'Lyon', 'Paris', 'Marseille']
})

# Filtre avec isin
paris = df[df['ville'].isin(['Paris', 'Lyon'])]

# Filtre avec contains (chaînes)
contains_a = df[df['nom'].str.contains('a', case=False)]

# Filtre avec query
filtered = df.query('âge > 30 and ville == "Paris"')
```

## Opérations sur les données

### Ajout de colonnes

```python
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})

# Nouvelle colonne simple
df['C'] = [7, 8, 9]

# Colonne calculée
df['D'] = df['A'] + df['B']

# Colonne conditionnelle
df['E'] = df['A'].apply(lambda x: 'pair' if x % 2 == 0 else 'impair')
```

### Modification de données

```python
# Modifier une valeur
df.loc[0, 'A'] = 10

# Modifier plusieurs valeurs
df.loc[df['A'] > 2, 'B'] = 99

# Remplacer des valeurs
df['A'].replace(1, 100, inplace=True)

# Remplacer avec mapping
df['ville'] = df['ville'].map({'Paris': 'PARIS', 'Lyon': 'LYON'})
```

### Gestion des valeurs manquantes

```python
df = pd.DataFrame({
    'A': [1, 2, None, 4],
    'B': [5, None, 7, 8]
})

# Détecter les valeurs manquantes
print(df.isna())
print(df.isna().sum())  # Nombre par colonne

# Supprimer les lignes avec NaN
df_clean = df.dropna()

# Remplacer les NaN
df_filled = df.fillna(0)  # Remplacer par 0
df_filled = df.fillna(df.mean())  # Remplacer par la moyenne
df_filled = df.fillna(method='ffill')  # Forward fill
```

## Agrégations et groupby

### Agrégations simples

```python
df = pd.DataFrame({
    'A': [1, 2, 3, 4],
    'B': [5, 6, 7, 8]
})

# Fonctions d'agrégation
print(df.sum())      # Somme par colonne
print(df.mean())     # Moyenne par colonne
print(df.max())      # Maximum par colonne
print(df.min())      # Minimum par colonne
print(df.std())      # Écart-type par colonne
print(df.count())    # Nombre de valeurs non-NaN
```

### Groupby

```python
df = pd.DataFrame({
    'ville': ['Paris', 'Lyon', 'Paris', 'Lyon', 'Paris'],
    'produit': ['A', 'A', 'B', 'B', 'A'],
    'ventes': [100, 150, 200, 120, 180]
})

# Grouper par ville
grouped = df.groupby('ville')
print(grouped.sum())

# Grouper par plusieurs colonnes
grouped = df.groupby(['ville', 'produit'])
print(grouped.sum())

# Agrégations multiples
result = df.groupby('ville').agg({
    'ventes': ['sum', 'mean', 'count']
})

# Fonctions personnalisées
result = df.groupby('ville')['ventes'].apply(lambda x: x.max() - x.min())
```

### Pivot tables

```python
df = pd.DataFrame({
    'ville': ['Paris', 'Lyon', 'Paris', 'Lyon'],
    'mois': ['Jan', 'Jan', 'Feb', 'Feb'],
    'ventes': [100, 150, 200, 120]
})

# Table pivot
pivot = df.pivot_table(
    values='ventes',
    index='ville',
    columns='mois',
    aggfunc='sum'
)
```

## Fusion et jointures

### Concaténation

```python
df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})

# Concaténation verticale
result = pd.concat([df1, df2], ignore_index=True)

# Concaténation horizontale
result = pd.concat([df1, df2], axis=1)
```

### Merge (jointures SQL)

```python
df1 = pd.DataFrame({
    'id': [1, 2, 3],
    'nom': ['Alice', 'Bob', 'Charlie']
})

df2 = pd.DataFrame({
    'id': [2, 3, 4],
    'ville': ['Paris', 'Lyon', 'Marseille']
})

# Inner join
result = pd.merge(df1, df2, on='id', how='inner')

# Left join
result = pd.merge(df1, df2, on='id', how='left')

# Right join
result = pd.merge(df1, df2, on='id', how='right')

# Outer join
result = pd.merge(df1, df2, on='id', how='outer')

# Jointure sur colonnes différentes
result = pd.merge(df1, df2, left_on='id', right_on='id', how='inner')
```

## Tri et réindexation

### Tri

```python
df = pd.DataFrame({
    'nom': ['Alice', 'Bob', 'Charlie'],
    'âge': [30, 25, 35],
    'ville': ['Paris', 'Lyon', 'Paris']
})

# Trier par une colonne
df_sorted = df.sort_values('âge')

# Trier par plusieurs colonnes
df_sorted = df.sort_values(['ville', 'âge'], ascending=[True, False])

# Trier par index
df_sorted = df.sort_index()
```

### Réindexation

```python
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})

# Réindexer
df_new = df.reindex([2, 0, 1])

# Réindexer avec nouvelles valeurs
df_new = df.reindex([0, 1, 2, 3], fill_value=0)
```

## Fonctions utiles

### Apply et map

```python
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})

# Appliquer une fonction à une colonne
df['C'] = df['A'].apply(lambda x: x * 2)

# Appliquer une fonction à chaque ligne
df['sum'] = df.apply(lambda row: row['A'] + row['B'], axis=1)

# Map avec dictionnaire
df['A_label'] = df['A'].map({1: 'un', 2: 'deux', 3: 'trois'})
```

### Valeurs uniques et comptage

```python
df = pd.DataFrame({
    'ville': ['Paris', 'Lyon', 'Paris', 'Lyon', 'Paris']
})

# Valeurs uniques
unique = df['ville'].unique()  # ['Paris' 'Lyon']

# Comptage de valeurs
counts = df['ville'].value_counts()
# Paris    3
# Lyon     2

# Nombre de valeurs uniques
n_unique = df['ville'].nunique()  # 2
```

## Exemples pratiques

### Exemple 1 : Analyse de ventes

```python
import pandas as pd

# Données de ventes
data = {
    'date': pd.date_range('2024-01-01', periods=10, freq='D'),
    'produit': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'B'],
    'ventes': [100, 150, 120, 80, 200, 110, 90, 180, 130, 160],
    'prix': [10, 15, 10, 20, 15, 10, 20, 15, 10, 15]
}

df = pd.DataFrame(data)

# Revenu total
df['revenu'] = df['ventes'] * df['prix']

# Ventes par produit
ventes_par_produit = df.groupby('produit')['ventes'].sum()

# Revenu moyen par jour
revenu_moyen = df.groupby(df['date'].dt.date)['revenu'].mean()

# Top 3 jours
top_days = df.nlargest(3, 'revenu')
```

### Exemple 2 : Nettoyage de données

```python
# Données avec problèmes
df = pd.DataFrame({
    'nom': ['Alice', 'Bob', None, 'Charlie', ''],
    'âge': [25, None, 30, 35, 40],
    'email': ['alice@example.com', 'bob@example.com', None, 'charlie@example.com', 'invalid']
})

# Nettoyer
# Supprimer les lignes avec nom vide ou None
df = df[df['nom'].notna() & (df['nom'] != '')]

# Remplacer les âges manquants par la moyenne
df['âge'] = df['âge'].fillna(df['âge'].mean())

# Valider les emails (simplifié)
df = df[df['email'].str.contains('@', na=False)]

print(df)
```

### Exemple 3 : Analyse temporelle

```python
# Données avec dates
df = pd.DataFrame({
    'date': pd.date_range('2024-01-01', periods=100, freq='D'),
    'valeur': np.random.randn(100)
})

# Définir la date comme index
df.set_index('date', inplace=True)

# Agrégation par mois
monthly = df.resample('M').mean()

# Agrégation par semaine
weekly = df.resample('W').sum()

# Rolling average (moyenne mobile)
df['rolling_mean'] = df['valeur'].rolling(window=7).mean()
```

## Bonnes pratiques

### 1. Utilisez la vectorisation

```python
# ✅ Bon : Vectorisé
df['C'] = df['A'] + df['B']

# ❌ Éviter : Boucle
for i in range(len(df)):
    df.loc[i, 'C'] = df.loc[i, 'A'] + df.loc[i, 'B']
```

### 2. Évitez les SettingWithCopyWarning

```python
# ✅ Bon
df = df[df['A'] > 0].copy()
df['B'] = df['B'] * 2

# ❌ Éviter
df[df['A'] > 0]['B'] = df['B'] * 2  # Warning!
```

### 3. Utilisez des types appropriés

```python
# ✅ Bon : Types optimisés
df['id'] = df['id'].astype('int32')
df['date'] = pd.to_datetime(df['date'])

# Économise de la mémoire
```

## Points clés à retenir

- ✅ Pandas fournit **Series** et **DataFrame** pour données structurées
- ✅ **Lecture/écriture** : CSV, Excel, JSON, SQL, etc.
- ✅ **Manipulation** : Filtrage, tri, groupby, merge
- ✅ **Performance** : Basé sur NumPy, optimisé
- ✅ **Fonctionnalités** : Gestion NaN, pivot, resampling
- ✅ **Intégration** : Compatible avec NumPy, matplotlib
- ✅ Parfait pour **analyse de données** et manipulation de données tabulaires

Pandas est l'outil essentiel pour travailler avec des données structurées en Python. Sa syntaxe intuitive et ses fonctionnalités puissantes en font le choix standard pour la data science.
